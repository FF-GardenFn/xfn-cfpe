{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "RL-O-CoV V2: Reinforcement Learning for Oscillatory Chain of Verification\n",
    "================================================================================\n",
    "\n",
    "LESSONS FROM V1 FAILURE:\n",
    "1. GSM8K too easy (88% baseline) - model doesn't need to oscillate\n",
    "2. Too many trainable params (342M @ 4.3%) with LR=3e-5 = catastrophic forgetting\n",
    "3. Goldilocks zone never hit (0%) - zone too narrow or similarity calc broken\n",
    "4. Loss went NEGATIVE = REINFORCE gradient exploded\n",
    "\n",
    "V2 FIXES:\n",
    "- Conservative hyperparameters (don't destroy baseline)\n",
    "- Harder datasets (force model to actually think)\n",
    "- Wider Goldilocks zone (easier to hit)\n",
    "- Better similarity logging (see actual values)\n",
    "- Preserve SemanticCapture with layer hooks (V1's key innovation)\n",
    "- Keep drift penalty\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# REPRODUCIBILITY (Issue #2: No seeding)\n",
    "# =============================================================================\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"Set all seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # Deterministic algorithms (slower but reproducible)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    try:\n",
    "        import transformers\n",
    "        transformers.set_seed(seed)\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    return seed\n",
    "\n",
    "\n",
    "def get_version_info() -> Dict[str, str]:\n",
    "    \"\"\"Capture versions for reproducibility\"\"\"\n",
    "    import sys\n",
    "    versions = {\n",
    "        \"python\": sys.version,\n",
    "        \"torch\": torch.__version__,\n",
    "        \"cuda\": torch.version.cuda if torch.cuda.is_available() else \"N/A\",\n",
    "    }\n",
    "    try:\n",
    "        import transformers\n",
    "        versions[\"transformers\"] = transformers.__version__\n",
    "    except ImportError:\n",
    "        pass\n",
    "    try:\n",
    "        import peft\n",
    "        versions[\"peft\"] = peft.__version__\n",
    "    except ImportError:\n",
    "        pass\n",
    "    try:\n",
    "        import bitsandbytes\n",
    "        versions[\"bitsandbytes\"] = bitsandbytes.__version__\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return versions\n"
   ],
   "id": "e8ecc0738bc74d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ============================================================================\n# CONFIGURATION - CONSERVATIVE (learned from V1 disaster)\n# ============================================================================\n\n@dataclass\nclass TrainingConfigV2:\n    \"\"\"Conservative config - learned from V1's catastrophic forgetting\"\"\"\n\n    # Model\n    model_name: str = \"Qwen/Qwen2-7B-Instruct\"\n\n    # SAFETY RAILS BACK ON\n    use_4bit: bool = True  # Was False in V1, caused OOM on gradients\n    bnb_4bit_compute_dtype: str = \"bfloat16\"\n    bnb_4bit_quant_type: str = \"nf4\"\n\n    # CONSERVATIVE LORA (V1 had r=128, way too high)\n    lora_r: int = 32              # Was 128\n    lora_alpha: int = 64          # 2x rank\n    lora_dropout: float = 0.1\n    target_modules: List[str] = field(default_factory=lambda: [\n        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"  # Attention only, not MLP\n    ])\n\n    # CONSERVATIVE TRAINING (V1 had lr=3e-5, exploded)\n    learning_rate: float = 5e-6   # Was 3e-5 (6x lower)\n    warmup_steps: int = 100       # NEW: gradual ramp-up\n    num_epochs: int = 3           # Was 5\n    batch_size: int = 2           # Was 4\n    gradient_accumulation_steps: int = 4\n    max_seq_length: int = 2048\n    max_new_tokens: int = 768\n    max_grad_norm: float = 0.5    # Was 1.0 (tighter clipping)\n\n    # SEMANTIC ANALYSIS\n    # V3 FIX: Layer 20 was too deep — at 71% depth, representations converge\n    # and hypothesis/oscillation sections always have similarity >0.86.\n    # Layer 14 (50% depth) retains more surface-level semantic differences.\n    analysis_layer: int = 14      # Was 20 (too deep, representations converge)\n    analysis_layers_to_log: List[int] = field(\n        default_factory=lambda: [8, 14, 20]  # Log multiple layers for calibration\n    )\n    use_first_sentence: bool = True  # Extract first sentence instead of mean-pooling entire section\n\n    # WIDER GOLDILOCKS ZONE\n    # V3 FIX: Ceiling raised from 0.85 to 0.95 — at layer 20, similarity was\n    # always >0.86 so the zone NEVER fired. Even at layer 14, sections about\n    # the same problem will be correlated; 0.95 gives room for the reward signal\n    # to exist while we calibrate the optimal layer.\n    goldilocks_low: float = 0.15  # Was 0.3\n    goldilocks_high: float = 0.95 # Was 0.85 (V2 ceiling was too low for layer 20)\n\n    # GENTLER REWARDS (prioritize not forgetting)\n    correctness_weight: float = 2.5   # Higher than V1\n    structure_weight: float = 1.5\n    resonance_reward: float = 1.5     # Was 2.0\n    drift_penalty_weight: float = 0.3 # Preserved from V1\n\n    # DATA (Issue #3: Config-driven split)\n    train_samples: int = 1000     # Was 2000\n    eval_samples: int = 100\n    train_split_ratio: float = 0.8  # For GSM8K train/eval split\n    hard_mix_ratio: float = 0.2     # Fraction of harder problems in training\n\n    # REPRODUCIBILITY (Issue #2)\n    seed: int = 42\n\n    # REINFORCE BASELINE (Issue #4: Variance reduction)\n    use_baseline: bool = True\n    baseline_ema_decay: float = 0.9  # EMA for reward baseline\n    normalize_advantages: bool = True  # Normalize (r - baseline)\n\n    # MISSING PHASE PENALTY (Issue #6)\n    missing_phase_penalty: float = 0.3  # Per missing required phase\n\n    # CHECKPOINTING (Issue #1)\n    save_every_n_steps: int = 200\n    save_on_best: bool = True\n\n    # EVALUATION\n    eval_every_n_steps: int = 50  # More frequent checks\n    num_eval_samples: int = 50\n\n    # LOGGING\n    log_every: int = 5\n    log_similarities: bool = True  # NEW: see actual cosine values\n\n    # OUTPUT\n    output_dir: str = \"./rl_ocov_v3_checkpoints\"\n",
   "id": "1149124dcda343cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# DIALECTICA PROMPT (same as V1)\n",
    "# ============================================================================\n",
    "\n",
    "TRAINING_PROMPT_TEMPLATE = \"\"\"Solve this problem using structured reasoning:\n",
    "\n",
    "{problem}\n",
    "\n",
    "Use this format:\n",
    "[DETECT] Is this complex reasoning or simple lookup?\n",
    "[HYPOTHESIZE]\n",
    "H1: [approach 1]\n",
    "H2: [approach 2]\n",
    "[OSCILLATION] Test each approach - what works, what fails?\n",
    "[SYNTHESIZE] Final answer based on analysis.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n"
   ],
   "id": "ec91edaac16aeb01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ============================================================================\n# SEMANTIC CAPTURE (PRESERVED FROM V1 - key innovation)\n# V3 FIX: Added first-sentence extraction + multi-layer support\n# ============================================================================\n\nclass SemanticCapture:\n    \"\"\"Extract semantic embeddings from specific transformer layers\"\"\"\n\n    def __init__(self, model, layer_idx: int):\n        self.model = model\n        self.layer_idx = layer_idx\n        self.captured = None\n        self.hook_handle = None\n\n    def _get_target_layer(self):\n        \"\"\"Find the target layer across different architectures\"\"\"\n        if hasattr(self.model, 'base_model'):\n            model = self.model.base_model.model  # PEFT wrapped\n        else:\n            model = self.model\n\n        # Qwen2, Llama, Mistral\n        if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n            return model.model.layers[self.layer_idx]\n        # GPT-2, GPT-Neo\n        elif hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n            return model.transformer.h[self.layer_idx]\n        else:\n            raise ValueError(f\"Unknown model architecture for {type(model)}\")\n\n    def _hook_fn(self, module, input, output):\n        if isinstance(output, tuple):\n            self.captured = output[0].detach()\n        else:\n            self.captured = output.detach()\n\n    def __enter__(self):\n        target_layer = self._get_target_layer()\n        self.hook_handle = target_layer.register_forward_hook(self._hook_fn)\n        return self\n\n    def __exit__(self, *args):\n        if self.hook_handle:\n            self.hook_handle.remove()\n\n    def get_embedding(self, input_ids: torch.Tensor) -> torch.Tensor:\n        \"\"\"Get mean-pooled embedding for the input\"\"\"\n        with torch.no_grad():\n            self.model(input_ids)\n\n        if self.captured is not None:\n            return self.captured.mean(dim=1).squeeze(0)\n        return None\n\n\ndef extract_first_sentence(text: str) -> str:\n    \"\"\"\n    Extract the first meaningful sentence from a section.\n    \n    V3 FIX: Mean-pooling entire sections washes out differences because\n    both hypothesis and oscillation discuss the same problem. The first\n    sentence captures the *framing* (\"I'll try algebra\" vs \"Testing: algebra\n    gives...\") which is where sections genuinely differ.\n    \"\"\"\n    # Strip the phase marker header\n    text = re.sub(r'^\\[?(?:HYPOTHESIZE|OSCILLATION|SYNTHESIZE|DETECT)\\]?\\s*:?\\s*', '', text.strip(), flags=re.IGNORECASE)\n    text = text.strip()\n    \n    if not text:\n        return text\n    \n    # Split on sentence boundaries\n    sentences = re.split(r'(?<=[.!?])\\s+', text)\n    \n    # Take first 1-2 sentences (at least 20 chars to be meaningful)\n    result = sentences[0] if sentences else text\n    if len(result) < 20 and len(sentences) > 1:\n        result = ' '.join(sentences[:2])\n    \n    # Cap at ~150 chars to keep it focused\n    if len(result) > 150:\n        result = result[:150]\n    \n    return result\n\n\ndef get_section_embedding(\n    text: str,\n    model,\n    tokenizer,\n    layer_idx: int,\n    max_length: int = 512,\n    first_sentence_only: bool = False\n) -> torch.Tensor:\n    \"\"\"\n    Get semantic embedding for a text section using layer hooks.\n    \n    Args:\n        first_sentence_only: If True, extract and embed only the first sentence\n            instead of the entire section. This preserves semantic differences\n            between sections that discuss the same problem differently.\n    \"\"\"\n\n    if not text or len(text.strip()) < 10:\n        hidden_size = model.config.hidden_size\n        device = next(model.parameters()).device\n        return torch.zeros(hidden_size, device=device)\n\n    # V3 FIX: Optionally extract first sentence for more discriminative embeddings\n    if first_sentence_only:\n        text = extract_first_sentence(text)\n        if not text or len(text.strip()) < 10:\n            hidden_size = model.config.hidden_size\n            device = next(model.parameters()).device\n            return torch.zeros(hidden_size, device=device)\n\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=max_length\n    ).to(next(model.parameters()).device)\n\n    with SemanticCapture(model, layer_idx) as capturer:\n        return capturer.get_embedding(inputs.input_ids)\n\n\ndef get_multi_layer_similarity(\n    text_a: str,\n    text_b: str,\n    model,\n    tokenizer,\n    layers: List[int],\n    first_sentence_only: bool = False\n) -> Dict[int, float]:\n    \"\"\"\n    Compute cosine similarity between two texts at multiple layers.\n    Used for calibration logging — helps find the optimal analysis layer.\n    \"\"\"\n    similarities = {}\n    for layer_idx in layers:\n        emb_a = get_section_embedding(text_a, model, tokenizer, layer_idx,\n                                       first_sentence_only=first_sentence_only)\n        emb_b = get_section_embedding(text_b, model, tokenizer, layer_idx,\n                                       first_sentence_only=first_sentence_only)\n        if emb_a is not None and emb_b is not None:\n            sim = F.cosine_similarity(emb_a.unsqueeze(0), emb_b.unsqueeze(0)).item()\n            similarities[layer_idx] = sim\n        else:\n            similarities[layer_idx] = None\n    return similarities\n",
   "id": "494dbf2972a068e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# DATA LOADING (with accessible datasets)\n",
    "# ============================================================================\n",
    "\n",
    "def load_gsm8k_data(path: str = None, num_samples: int = None) -> List[Dict]:\n",
    "    \"\"\"Load GSM8K dataset - supports local JSONL or HuggingFace download\"\"\"\n",
    "    \n",
    "    processed = []\n",
    "    \n",
    "    # Try local file first\n",
    "    if path and os.path.exists(path):\n",
    "        print(f\"Loading GSM8K from local file: {path}\")\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "                answer_text = item.get(\"answer\", \"\")\n",
    "                if \"####\" in answer_text:\n",
    "                    final_answer = answer_text.split(\"####\")[-1].strip()\n",
    "                else:\n",
    "                    numbers = re.findall(r'-?\\d+\\.?\\d*', answer_text)\n",
    "                    final_answer = numbers[-1] if numbers else answer_text\n",
    "\n",
    "                processed.append({\n",
    "                    \"question\": item[\"question\"],\n",
    "                    \"answer\": final_answer,\n",
    "                    \"full_solution\": answer_text,\n",
    "                    \"difficulty\": 1,\n",
    "                    \"source\": \"gsm8k_local\"\n",
    "                })\n",
    "    else:\n",
    "        # Fallback to HuggingFace download\n",
    "        from datasets import load_dataset\n",
    "        print(\"Loading GSM8K dataset from HuggingFace...\")\n",
    "        dataset = load_dataset(\"gsm8k\", \"main\", split=\"train\")\n",
    "\n",
    "        for item in dataset:\n",
    "            answer_text = item.get(\"answer\", \"\")\n",
    "            if \"####\" in answer_text:\n",
    "                final_answer = answer_text.split(\"####\")[-1].strip()\n",
    "            else:\n",
    "                numbers = re.findall(r'-?\\d+\\.?\\d*', answer_text)\n",
    "                final_answer = numbers[-1] if numbers else answer_text\n",
    "\n",
    "            processed.append({\n",
    "                \"question\": item[\"question\"],\n",
    "                \"answer\": final_answer,\n",
    "                \"full_solution\": answer_text,\n",
    "                \"difficulty\": 1,\n",
    "                \"source\": \"gsm8k\"\n",
    "            })\n",
    "\n",
    "    if num_samples:\n",
    "        processed = processed[:num_samples]\n",
    "\n",
    "    print(f\"Loaded {len(processed)} GSM8K examples\")\n",
    "    return processed\n",
    "\n",
    "\n",
    "def load_harder_math_data(path: str = None, num_samples: int = 200) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Load harder math problems - supports local MATH-500 JSONL or HuggingFace download\n",
    "    \n",
    "    Primary: local math_500.jsonl (if path provided)\n",
    "    Fallback 1: HuggingFace MATH-500\n",
    "    Fallback 2: GSM8K test set\n",
    "    Fallback 3: synthetic problems\n",
    "    \"\"\"\n",
    "    \n",
    "    processed = []\n",
    "\n",
    "    # Try local MATH-500 file first\n",
    "    if path and os.path.exists(path):\n",
    "        print(f\"Loading MATH-500 from local file: {path}\")\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                for line in f:\n",
    "                    if len(processed) >= num_samples:\n",
    "                        break\n",
    "                    item = json.loads(line)\n",
    "                    processed.append({\n",
    "                        \"question\": item.get(\"problem\", item.get(\"question\", \"\")),\n",
    "                        \"answer\": item.get(\"answer\", \"\"),\n",
    "                        \"full_solution\": item.get(\"solution\", \"\"),\n",
    "                        \"difficulty\": item.get(\"level\", 3),\n",
    "                        \"source\": \"math500_local\"\n",
    "                    })\n",
    "            print(f\"Loaded {len(processed)} MATH-500 examples from local file\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load local MATH-500: {e}\")\n",
    "\n",
    "    # Fallback 1: Try HuggingFace MATH-500\n",
    "    if len(processed) < num_samples:\n",
    "        try:\n",
    "            from datasets import load_dataset\n",
    "            print(\"Trying HuggingFace MATH-500 dataset...\")\n",
    "            dataset = load_dataset(\"HuggingFaceH4/MATH-500\", split=\"test\")\n",
    "\n",
    "            for item in dataset:\n",
    "                if len(processed) >= num_samples:\n",
    "                    break\n",
    "                processed.append({\n",
    "                    \"question\": item.get(\"problem\", \"\"),\n",
    "                    \"answer\": item.get(\"answer\", \"\"),\n",
    "                    \"full_solution\": item.get(\"solution\", \"\"),\n",
    "                    \"difficulty\": item.get(\"level\", 3),\n",
    "                    \"source\": \"math500_hf\"\n",
    "                })\n",
    "            print(f\"Loaded {len(processed)} MATH-500 examples from HuggingFace\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"HuggingFace MATH-500 failed: {e}\")\n",
    "\n",
    "    # Fallback 2: Try GSM8K test set (harder than train)\n",
    "    if len(processed) < num_samples:\n",
    "        try:\n",
    "            from datasets import load_dataset\n",
    "            print(\"Trying GSM8K test set as harder problems...\")\n",
    "            dataset = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
    "\n",
    "            for item in dataset:\n",
    "                if len(processed) >= num_samples:\n",
    "                    break\n",
    "                answer_text = item.get(\"answer\", \"\")\n",
    "                if \"####\" in answer_text:\n",
    "                    final_answer = answer_text.split(\"####\")[-1].strip()\n",
    "                else:\n",
    "                    numbers = re.findall(r'-?\\d+\\.?\\d*', answer_text)\n",
    "                    final_answer = numbers[-1] if numbers else \"\"\n",
    "\n",
    "                processed.append({\n",
    "                    \"question\": item[\"question\"],\n",
    "                    \"answer\": final_answer,\n",
    "                    \"difficulty\": 2,\n",
    "                    \"source\": \"gsm8k_test\"\n",
    "                })\n",
    "\n",
    "            print(f\"Total examples: {len(processed)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"GSM8K test failed: {e}\")\n",
    "\n",
    "    # Fallback 3: Add synthetic olympiad-style problems\n",
    "    if len(processed) < num_samples:\n",
    "        print(\"Adding synthetic hard problems...\")\n",
    "        synthetic = generate_synthetic_hard_problems(num_samples - len(processed))\n",
    "        processed.extend(synthetic)\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "def generate_synthetic_hard_problems(n: int) -> List[Dict]:\n",
    "    \"\"\"Generate synthetic hard problems that require multi-step reasoning\"\"\"\n",
    "\n",
    "    problems = [\n",
    "        {\n",
    "            \"question\": \"Find the sum of all positive integers n such that n² + 12n - 2007 is a perfect square.\",\n",
    "            \"answer\": \"80\",\n",
    "            \"difficulty\": 3\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How many ordered pairs of positive integers (a,b) satisfy 1/a + 1/b = 1/20?\",\n",
    "            \"answer\": \"9\",\n",
    "            \"difficulty\": 3\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"In triangle ABC, AB=13, BC=14, CA=15. Find the length of the altitude from A to BC.\",\n",
    "            \"answer\": \"12\",\n",
    "            \"difficulty\": 3\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Find the last three digits of 7^999.\",\n",
    "            \"answer\": \"343\",\n",
    "            \"difficulty\": 3\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How many positive integers less than 1000 are divisible by neither 5 nor 7?\",\n",
    "            \"answer\": \"686\",\n",
    "            \"difficulty\": 3\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"A sequence is defined by a₁=1, a₂=2, and aₙ=aₙ₋₁+aₙ₋₂ for n≥3. Find a₁₀.\",\n",
    "            \"answer\": \"89\",\n",
    "            \"difficulty\": 2\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Find the sum of all prime factors of 2310.\",\n",
    "            \"answer\": \"28\",\n",
    "            \"difficulty\": 2\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"If x + 1/x = 5, find x² + 1/x².\",\n",
    "            \"answer\": \"23\",\n",
    "            \"difficulty\": 2\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How many 4-digit numbers have all distinct digits?\",\n",
    "            \"answer\": \"4536\",\n",
    "            \"difficulty\": 2\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Find the GCD of 48 and 180.\",\n",
    "            \"answer\": \"12\",\n",
    "            \"difficulty\": 1\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        prob = problems[i % len(problems)].copy()\n",
    "        prob[\"source\"] = \"synthetic\"\n",
    "        result.append(prob)\n",
    "\n",
    "    return result\n",
    "\n"
   ],
   "id": "90ab4c9f811d5102"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ============================================================================\n# REWARD CALCULATOR (PRESERVED FROM V1 + V3 fixes for Goldilocks)\n# ============================================================================\n\nclass OCovRewardCalculator:\n    \"\"\"\n    Calculate rewards for O-CoV training (preserved from V1):\n    - Terminal accuracy\n    - Structural integrity (phase markers)\n    - Resonance (Goldilocks zone for hypothesis-oscillation similarity)\n    - Drift penalty (staying on topic)\n    \n    V3 FIXES:\n    - First-sentence extraction for more discriminative embeddings\n    - Multi-layer similarity logging for calibration\n    - Layer 14 instead of 20 (mid-network, more diverse representations)\n    - Goldilocks ceiling 0.95 (was 0.85 — never fired at layer 20)\n    \"\"\"\n\n    def __init__(self, model, tokenizer, config: TrainingConfigV2):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.config = config\n        self.device = next(model.parameters()).device\n\n        # Phase markers to detect\n        self.phases = [\"DETECT\", \"HYPOTHESIZE\", \"OSCILLATION\", \"SYNTHESIZE\"]\n\n        # Tracking for analysis\n        self.similarity_history = []\n        self.accuracy_history = []\n        \n        # V3: Multi-layer similarity tracking for calibration\n        self.multi_layer_history = {layer: [] for layer in config.analysis_layers_to_log}\n\n    def extract_answer(self, text: str) -> str:\n        \"\"\"Extract the final answer from generated text\"\"\"\n        if \"Answer:\" in text:\n            answer_part = text.split(\"Answer:\")[-1].strip()\n            lines = answer_part.split('\\n')\n            answer = lines[0].strip()\n        elif \"SYNTHESIZE\" in text.upper():\n            synth_part = text.upper().split(\"SYNTHESIZE\")[-1]\n            numbers = re.findall(r'-?\\d+\\.?\\d*', synth_part)\n            answer = numbers[-1] if numbers else \"\"\n        else:\n            numbers = re.findall(r'-?\\d+\\.?\\d*', text)\n            answer = numbers[-1] if numbers else \"\"\n\n        return answer.strip()\n\n    def check_accuracy(self, generated: str, expected: str) -> float:\n        \"\"\"Check if the generated answer matches expected\"\"\"\n        gen_answer = self.extract_answer(generated)\n\n        gen_clean = re.sub(r'[^\\d.-]', '', gen_answer)\n        exp_clean = re.sub(r'[^\\d.-]', '', expected)\n\n        try:\n            gen_num = float(gen_clean) if gen_clean else None\n            exp_num = float(exp_clean) if exp_clean else None\n\n            if gen_num is not None and exp_num is not None:\n                if abs(gen_num - exp_num) < 0.01:\n                    return self.config.correctness_weight\n                if exp_num != 0 and abs(gen_num - exp_num) / abs(exp_num) < 0.1:\n                    return self.config.correctness_weight * 0.5\n        except ValueError:\n            pass\n\n        if gen_clean == exp_clean:\n            return self.config.correctness_weight\n\n        return -1.0  # Wrong answer penalty\n\n    def check_structure(self, text: str) -> Tuple[float, Dict[str, bool]]:\n        \"\"\"Check structural integrity (phase markers present)\"\"\"\n        found = {}\n        text_upper = text.upper()\n\n        for phase in self.phases:\n            patterns = [f\"[{phase}]\", f\"**{phase}**\", f\"{phase}:\", f\"## {phase}\"]\n            found[phase] = any(p.upper() in text_upper for p in patterns)\n\n        # Check for hypothesis markers\n        hypothesis_patterns = [r\"H1[:\\s]\", r\"H2[:\\s]\", r\"\\*\\*H1\\*\\*\", r\"\\*\\*H2\\*\\*\"]\n        found[\"HYPOTHESES\"] = any(re.search(p, text, re.IGNORECASE) for p in hypothesis_patterns)\n\n        phase_score = sum(found.values()) / (len(self.phases) + 1)\n        reward = phase_score * self.config.structure_weight\n\n        return reward, found\n\n    def extract_sections(self, text: str) -> Dict[str, str]:\n        \"\"\"Extract hypothesis and oscillation sections\"\"\"\n        sections = {\"hypothesis\": \"\", \"oscillation\": \"\", \"synthesize\": \"\"}\n        text_upper = text.upper()\n\n        # Find HYPOTHESIZE section\n        if \"HYPOTHESIZE\" in text_upper:\n            start = text_upper.find(\"HYPOTHESIZE\")\n            end = len(text)\n            for next_phase in [\"OSCILLATION\", \"SYNTHESIZE\", \"SYNTHESIS\"]:\n                idx = text_upper.find(next_phase, start + 10)\n                if idx > 0:\n                    end = min(end, idx)\n            sections[\"hypothesis\"] = text[start:end]\n\n        # Find OSCILLATION section\n        if \"OSCILLATION\" in text_upper:\n            start = text_upper.find(\"OSCILLATION\")\n            end = len(text)\n            for next_phase in [\"SYNTHESIZE\", \"SYNTHESIS\", \"ANSWER\"]:\n                idx = text_upper.find(next_phase, start + 10)\n                if idx > 0:\n                    end = min(end, idx)\n            sections[\"oscillation\"] = text[start:end]\n\n        # Find SYNTHESIZE section\n        for marker in [\"SYNTHESIZE\", \"SYNTHESIS\"]:\n            if marker in text_upper:\n                start = text_upper.find(marker)\n                sections[\"synthesize\"] = text[start:]\n                break\n\n        return sections\n\n    def calculate_resonance(self, text: str, problem_embedding: torch.Tensor) -> Tuple[float, Dict]:\n        \"\"\"\n        Calculate resonance reward (THE KEY INNOVATION from V1)\n\n        Goldilocks Zone: hypothesis and oscillation should be\n        related but different (0.15 < similarity < 0.95)\n        \n        V3 FIXES:\n        - Uses first-sentence extraction for more discriminative comparison\n        - Logs similarity at multiple layers for calibration\n        - Layer 14 (mid-network) instead of 20 (too deep)\n        \"\"\"\n        sections = self.extract_sections(text)\n        metrics = {\n            \"hyp_osc_similarity\": None,\n            \"in_goldilocks\": False,\n            \"drift\": 0.0,\n            \"multi_layer_sim\": {},  # V3: per-layer similarities for calibration\n        }\n\n        hyp_text = sections[\"hypothesis\"]\n        osc_text = sections[\"oscillation\"]\n\n        if len(hyp_text) < 20 or len(osc_text) < 20:\n            return 0.0, metrics\n\n        # V3: Use first-sentence extraction if configured\n        use_first = self.config.use_first_sentence\n\n        # Get embeddings at the primary analysis layer\n        hyp_emb = get_section_embedding(\n            hyp_text, self.model, self.tokenizer,\n            self.config.analysis_layer,\n            first_sentence_only=use_first\n        )\n        osc_emb = get_section_embedding(\n            osc_text, self.model, self.tokenizer,\n            self.config.analysis_layer,\n            first_sentence_only=use_first\n        )\n\n        if hyp_emb is None or osc_emb is None:\n            return 0.0, metrics\n\n        # Calculate cosine similarity at primary layer\n        similarity = F.cosine_similarity(hyp_emb.unsqueeze(0), osc_emb.unsqueeze(0)).item()\n        metrics[\"hyp_osc_similarity\"] = similarity\n        self.similarity_history.append(similarity)\n\n        # V3: Multi-layer calibration logging (every 10th step to save compute)\n        if len(self.similarity_history) % 10 == 1:\n            multi_sim = get_multi_layer_similarity(\n                hyp_text, osc_text,\n                self.model, self.tokenizer,\n                self.config.analysis_layers_to_log,\n                first_sentence_only=use_first\n            )\n            metrics[\"multi_layer_sim\"] = multi_sim\n            for layer_idx, sim_val in multi_sim.items():\n                if sim_val is not None:\n                    self.multi_layer_history[layer_idx].append(sim_val)\n\n        # THE GOLDILOCKS ZONE (V3: widened ceiling to 0.95)\n        resonance_reward = 0.0\n        if self.config.goldilocks_low < similarity < self.config.goldilocks_high:\n            resonance_reward = self.config.resonance_reward\n            metrics[\"in_goldilocks\"] = True\n\n            # Bonus for being closer to middle of zone\n            zone_center = (self.config.goldilocks_low + self.config.goldilocks_high) / 2\n            distance_from_center = abs(similarity - zone_center)\n            max_distance = (self.config.goldilocks_high - self.config.goldilocks_low) / 2\n            centering_bonus = (1 - distance_from_center / max_distance) * 0.3\n            resonance_reward += centering_bonus\n\n        # Calculate drift (PRESERVED FROM V1)\n        if problem_embedding is not None:\n            full_emb = get_section_embedding(\n                text, self.model, self.tokenizer,\n                self.config.analysis_layer\n            )\n            if full_emb is not None:\n                drift = 1.0 - F.cosine_similarity(\n                    full_emb.unsqueeze(0), problem_embedding.unsqueeze(0)\n                ).item()\n                metrics[\"drift\"] = drift\n                resonance_reward -= drift * self.config.drift_penalty_weight\n\n        return resonance_reward, metrics\n\n    def calculate_reward(\n        self,\n        generated_text: str,\n        expected_answer: str,\n        problem_text: str\n    ) -> Tuple[float, Dict]:\n        \"\"\"Calculate total reward: accuracy + structure + resonance - drift\"\"\"\n\n        # Get problem embedding for drift calculation\n        problem_emb = get_section_embedding(\n            problem_text, self.model, self.tokenizer,\n            self.config.analysis_layer\n        )\n\n        # 1. Accuracy reward\n        accuracy_reward = self.check_accuracy(generated_text, expected_answer)\n        self.accuracy_history.append(accuracy_reward > 0)\n\n        # 2. Structure reward\n        structure_reward, structure_details = self.check_structure(generated_text)\n\n        # 3. Resonance reward (includes drift penalty)\n        resonance_reward, resonance_metrics = self.calculate_resonance(\n            generated_text, problem_emb\n        )\n\n        # Total reward\n        total_reward = accuracy_reward + structure_reward + resonance_reward\n\n        metrics = {\n            \"total_reward\": total_reward,\n            \"accuracy_reward\": accuracy_reward,\n            \"structure_reward\": structure_reward,\n            \"resonance_reward\": resonance_reward,\n            \"structure_found\": structure_details,\n            **resonance_metrics\n        }\n\n        return total_reward, metrics\n\n    def get_stats(self) -> Dict:\n        \"\"\"Get statistics for logging\"\"\"\n        stats = {}\n\n        if self.similarity_history:\n            sims = self.similarity_history[-100:]  # Last 100\n            stats[\"sim_mean\"] = sum(sims) / len(sims)\n            stats[\"sim_min\"] = min(sims)\n            stats[\"sim_max\"] = max(sims)\n            stats[\"goldilocks_rate\"] = sum(\n                1 for s in sims\n                if self.config.goldilocks_low < s < self.config.goldilocks_high\n            ) / len(sims)\n\n        if self.accuracy_history:\n            stats[\"accuracy\"] = sum(self.accuracy_history[-100:]) / min(100, len(self.accuracy_history))\n\n        # V3: Multi-layer stats for calibration\n        for layer_idx, layer_sims in self.multi_layer_history.items():\n            if layer_sims:\n                recent = layer_sims[-20:]\n                stats[f\"sim_L{layer_idx}_mean\"] = sum(recent) / len(recent)\n                stats[f\"sim_L{layer_idx}_min\"] = min(recent)\n                stats[f\"sim_L{layer_idx}_max\"] = max(recent)\n\n        return stats\n",
   "id": "b9cfece4f38dc748"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# TRAINER (with warmup and catastrophe detection)\n",
    "# ============================================================================\n",
    "\n",
    "class RLOCovTrainerV2:\n",
    "    \"\"\"RL trainer with safety mechanisms to prevent catastrophic forgetting\"\"\"\n",
    "\n",
    "    def __init__(self, model, tokenizer, config: TrainingConfigV2):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config\n",
    "        self.device = next(model.parameters()).device\n",
    "\n",
    "        # Reward calculator\n",
    "        self.reward_calc = OCovRewardCalculator(model, tokenizer, config)\n",
    "\n",
    "        # Optimizer\n",
    "        trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            trainable_params,\n",
    "            lr=config.learning_rate,\n",
    "            weight_decay=0.01\n",
    "        )\n",
    "\n",
    "        # Training state\n",
    "        self.global_step = 0\n",
    "        self.best_accuracy = 0\n",
    "        self.initial_accuracy = None\n",
    "\n",
    "        # REINFORCE baseline (Issue #4: Variance reduction)\n",
    "        self.reward_baseline = 0.0\n",
    "        self.reward_history_for_norm = []  # For advantage normalization\n",
    "\n",
    "        # History\n",
    "        self.history = {\n",
    "            \"step\": [], \"loss\": [], \"reward\": [], \"advantage\": [],\n",
    "            \"accuracy\": [], \"structure\": [], \"resonance\": [],\n",
    "            \"goldilocks_rate\": [], \"similarity\": [], \"missing_phases\": []\n",
    "        }\n",
    "\n",
    "        # Metrics log for JSONL output (Issue #1)\n",
    "        self.metrics_log = []\n",
    "\n",
    "    def save_checkpoint(self, path: str, is_best: bool = False):\n",
    "        \"\"\"Save LoRA adapter, tokenizer, config, and metrics (Issue #1)\"\"\"\n",
    "        import os\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        # 1. Save LoRA adapter weights\n",
    "        adapter_path = os.path.join(path, \"adapter\")\n",
    "        self.model.save_pretrained(adapter_path)\n",
    "        print(f\"  ✓ Saved LoRA adapter to {adapter_path}\")\n",
    "\n",
    "        # 2. Save tokenizer\n",
    "        tokenizer_path = os.path.join(path, \"tokenizer\")\n",
    "        self.tokenizer.save_pretrained(tokenizer_path)\n",
    "        print(f\"  ✓ Saved tokenizer to {tokenizer_path}\")\n",
    "\n",
    "        # 3. Save config snapshot\n",
    "        config_snapshot = {\n",
    "            \"config\": asdict(self.config),\n",
    "            \"versions\": get_version_info(),\n",
    "            \"global_step\": self.global_step,\n",
    "            \"best_accuracy\": self.best_accuracy,\n",
    "            \"initial_accuracy\": self.initial_accuracy,\n",
    "            \"reward_baseline\": self.reward_baseline,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"is_best\": is_best,\n",
    "        }\n",
    "        config_path = os.path.join(path, \"config_snapshot.json\")\n",
    "        with open(config_path, \"w\") as f:\n",
    "            json.dump(config_snapshot, f, indent=2, default=str)\n",
    "        print(f\"  ✓ Saved config snapshot to {config_path}\")\n",
    "\n",
    "        # 4. Save metrics JSONL\n",
    "        metrics_path = os.path.join(path, \"metrics.jsonl\")\n",
    "        with open(metrics_path, \"w\") as f:\n",
    "            for entry in self.metrics_log:\n",
    "                f.write(json.dumps(entry) + \"\\n\")\n",
    "        print(f\"  ✓ Saved {len(self.metrics_log)} metric entries to {metrics_path}\")\n",
    "\n",
    "    def format_prompt(self, problem: str) -> str:\n",
    "        return TRAINING_PROMPT_TEMPLATE.format(problem=problem)\n",
    "\n",
    "    def generate(self, prompt: str) -> Tuple[str, torch.Tensor]:\n",
    "        \"\"\"Generate response\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=self.config.max_seq_length - self.config.max_new_tokens\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=self.config.max_new_tokens,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_p=0.95,\n",
    "                pad_token_id=self.tokenizer.pad_token_id,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True\n",
    "            )\n",
    "\n",
    "        generated_ids = outputs.sequences[0]\n",
    "        generated_text = self.tokenizer.decode(\n",
    "            generated_ids[inputs.input_ids.shape[1]:],\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        return generated_text, generated_ids\n",
    "\n",
    "    def compute_policy_gradient_loss(\n",
    "        self,\n",
    "        full_sequence: torch.Tensor,\n",
    "        prompt_length: int,\n",
    "        reward: float\n",
    "    ) -> Tuple[torch.Tensor, float]:\n",
    "        \"\"\"REINFORCE policy gradient loss with baseline (Issue #4)\"\"\"\n",
    "\n",
    "        outputs = self.model(full_sequence.unsqueeze(0))\n",
    "        logits = outputs.logits\n",
    "\n",
    "        shift_logits = logits[..., :-1, :].contiguous()\n",
    "        shift_labels = full_sequence[1:].contiguous()\n",
    "\n",
    "        log_probs = F.log_softmax(shift_logits, dim=-1)\n",
    "        token_log_probs = log_probs[0, torch.arange(len(shift_labels)), shift_labels]\n",
    "\n",
    "        # MASK SANITY CHECK (Issue #7: off-by-one risk)\n",
    "        # prompt_length is the number of tokens in the prompt\n",
    "        # We want to mask generated tokens only (indices >= prompt_length in shift_labels)\n",
    "        # shift_labels has length (seq_len - 1), corresponding to predictions for positions 1..seq_len\n",
    "        # So mask should be 1 for positions where we're predicting generated tokens\n",
    "        mask = torch.zeros_like(token_log_probs)\n",
    "        # After shifting: position i predicts token i+1\n",
    "        # Prompt occupies positions 0..prompt_length-1, so generated starts at prompt_length\n",
    "        # In shifted space: we want positions prompt_length-1 onwards (predicting tokens prompt_length+)\n",
    "        gen_start = max(0, prompt_length - 1)\n",
    "        mask[gen_start:] = 1.0\n",
    "\n",
    "        # DEBUG: log mask coverage on first step\n",
    "        if self.global_step == 0:\n",
    "            print(f\"  [DEBUG] prompt_length={prompt_length}, seq_len={len(full_sequence)}, \"\n",
    "                  f\"mask_start={gen_start}, masked_tokens={int(mask.sum().item())}\")\n",
    "\n",
    "        # BASELINE AND ADVANTAGE (Issue #4: Variance reduction)\n",
    "        if self.config.use_baseline:\n",
    "            # Update EMA baseline\n",
    "            self.reward_baseline = (\n",
    "                self.config.baseline_ema_decay * self.reward_baseline +\n",
    "                (1 - self.config.baseline_ema_decay) * reward\n",
    "            )\n",
    "            advantage = reward - self.reward_baseline\n",
    "\n",
    "            # Optional advantage normalization\n",
    "            if self.config.normalize_advantages:\n",
    "                self.reward_history_for_norm.append(reward)\n",
    "                if len(self.reward_history_for_norm) > 100:\n",
    "                    self.reward_history_for_norm.pop(0)\n",
    "                if len(self.reward_history_for_norm) > 1:\n",
    "                    std = np.std(self.reward_history_for_norm) + 1e-8\n",
    "                    advantage = advantage / std\n",
    "        else:\n",
    "            advantage = reward\n",
    "\n",
    "        # Clamp advantage to prevent explosion\n",
    "        advantage = max(-5.0, min(5.0, advantage))\n",
    "\n",
    "        # WARMUP: scale down learning signal early\n",
    "        warmup_scale = min(1.0, self.global_step / self.config.warmup_steps)\n",
    "\n",
    "        masked_log_probs = token_log_probs * mask\n",
    "        policy_loss = -advantage * warmup_scale * masked_log_probs.sum() / mask.sum().clamp(min=1)\n",
    "\n",
    "        # Entropy bonus for exploration\n",
    "        probs = F.softmax(shift_logits[0], dim=-1)\n",
    "        entropy = -(probs * log_probs[0]).sum(dim=-1)\n",
    "        entropy_bonus = 0.01 * (entropy * mask).mean()\n",
    "\n",
    "        return policy_loss - entropy_bonus, advantage\n",
    "\n",
    "    def train_step(self, problem: str, expected_answer: str) -> Dict:\n",
    "        \"\"\"Single training step with safety checks\"\"\"\n",
    "\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        prompt = self.format_prompt(problem)\n",
    "        prompt_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        prompt_length = prompt_ids.shape[1]\n",
    "\n",
    "        generated_text, full_sequence = self.generate(prompt)\n",
    "        reward, metrics = self.reward_calc.calculate_reward(\n",
    "            generated_text, expected_answer, problem\n",
    "        )\n",
    "\n",
    "        # MISSING PHASE PENALTY (Issue #6)\n",
    "        missing_phases = sum(1 for phase, found in metrics[\"structure_found\"].items() if not found)\n",
    "        if missing_phases > 0:\n",
    "            phase_penalty = missing_phases * self.config.missing_phase_penalty\n",
    "            reward -= phase_penalty\n",
    "            metrics[\"missing_phase_penalty\"] = phase_penalty\n",
    "        else:\n",
    "            metrics[\"missing_phase_penalty\"] = 0.0\n",
    "\n",
    "        loss, advantage = self.compute_policy_gradient_loss(full_sequence, prompt_length, reward)\n",
    "        loss.backward()\n",
    "\n",
    "        # Tight gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            [p for p in self.model.parameters() if p.requires_grad],\n",
    "            max_norm=self.config.max_grad_norm\n",
    "        )\n",
    "\n",
    "        self.optimizer.step()\n",
    "        self.global_step += 1\n",
    "\n",
    "        # Record history\n",
    "        self.history[\"step\"].append(self.global_step)\n",
    "        self.history[\"loss\"].append(loss.item())\n",
    "        self.history[\"reward\"].append(reward)\n",
    "        self.history[\"advantage\"].append(advantage)\n",
    "        self.history[\"accuracy\"].append(metrics[\"accuracy_reward\"])\n",
    "        self.history[\"structure\"].append(metrics[\"structure_reward\"])\n",
    "        self.history[\"resonance\"].append(metrics[\"resonance_reward\"])\n",
    "        self.history[\"goldilocks_rate\"].append(1.0 if metrics[\"in_goldilocks\"] else 0.0)\n",
    "        self.history[\"missing_phases\"].append(missing_phases)\n",
    "        if metrics[\"hyp_osc_similarity\"] is not None:\n",
    "            self.history[\"similarity\"].append(metrics[\"hyp_osc_similarity\"])\n",
    "\n",
    "        # Log to metrics JSONL (Issue #1)\n",
    "        self.metrics_log.append({\n",
    "            \"step\": self.global_step,\n",
    "            \"loss\": loss.item(),\n",
    "            \"reward\": reward,\n",
    "            \"advantage\": advantage,\n",
    "            \"missing_phases\": missing_phases,\n",
    "            \"in_goldilocks\": metrics[\"in_goldilocks\"],\n",
    "            \"accuracy_reward\": metrics[\"accuracy_reward\"],\n",
    "            \"similarity\": metrics.get(\"hyp_osc_similarity\"),\n",
    "        })\n",
    "\n",
    "        return {\"loss\": loss.item(), \"reward\": reward, \"advantage\": advantage, \"metrics\": metrics}\n",
    "\n",
    "    def evaluate(self, eval_data: List[Dict], num_samples: int = None) -> Dict:\n",
    "        \"\"\"Evaluate model\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        if num_samples:\n",
    "            eval_data = random.sample(eval_data, min(num_samples, len(eval_data)))\n",
    "\n",
    "        results = {\n",
    "            \"accuracy\": 0, \"structure_rate\": 0,\n",
    "            \"goldilocks_rate\": 0, \"avg_reward\": 0,\n",
    "            \"similarities\": []\n",
    "        }\n",
    "\n",
    "        for item in eval_data:\n",
    "            prompt = self.format_prompt(item[\"question\"])\n",
    "            generated_text, _ = self.generate(prompt)\n",
    "            reward, metrics = self.reward_calc.calculate_reward(\n",
    "                generated_text, item[\"answer\"], item[\"question\"]\n",
    "            )\n",
    "\n",
    "            results[\"accuracy\"] += 1 if metrics[\"accuracy_reward\"] > 0 else 0\n",
    "            results[\"structure_rate\"] += sum(metrics[\"structure_found\"].values()) / len(metrics[\"structure_found\"])\n",
    "            results[\"goldilocks_rate\"] += 1 if metrics[\"in_goldilocks\"] else 0\n",
    "            results[\"avg_reward\"] += reward\n",
    "            if metrics[\"hyp_osc_similarity\"] is not None:\n",
    "                results[\"similarities\"].append(metrics[\"hyp_osc_similarity\"])\n",
    "\n",
    "        n = len(eval_data)\n",
    "        results[\"accuracy\"] = results[\"accuracy\"] / n * 100\n",
    "        results[\"structure_rate\"] = results[\"structure_rate\"] / n * 100\n",
    "        results[\"goldilocks_rate\"] = results[\"goldilocks_rate\"] / n * 100\n",
    "        results[\"avg_reward\"] = results[\"avg_reward\"] / n\n",
    "\n",
    "        self.model.train()\n",
    "        return results\n",
    "\n"
   ],
   "id": "79bcb680991d7f05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ============================================================================\n# MAIN TRAINING LOOP\n# ============================================================================\n\ndef main():\n    \"\"\"Main execution with safety checks\"\"\"\n\n    from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n    from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n\n    config = TrainingConfigV2()\n\n    # REPRODUCIBILITY (Issue #2)\n    set_seed(config.seed)\n    versions = get_version_info()\n\n    print(\"=\" * 70)\n    print(\"RL-O-CoV V3: GOLDILOCKS FIX\")\n    print(\"   V2 had 0% Goldilocks rate — similarity always >0.86 at layer 20\")\n    print(\"   V3 fixes: layer 14, first-sentence extraction, ceiling 0.95\")\n    print(\"=\" * 70)\n    print(f\"\\nConfiguration:\")\n    print(f\"  Model: {config.model_name}\")\n    print(f\"  Precision: {'4-bit' if config.use_4bit else 'bfloat16'}\")\n    print(f\"  LoRA rank: {config.lora_r} (V1 had 128)\")\n    print(f\"  Learning rate: {config.learning_rate} (V1 had 3e-5)\")\n    print(f\"  Warmup steps: {config.warmup_steps}\")\n    print(f\"  Analysis layer: {config.analysis_layer} (V2 had 20 — too deep)\")\n    print(f\"  First-sentence extraction: {config.use_first_sentence}\")\n    print(f\"  Goldilocks Zone: [{config.goldilocks_low}, {config.goldilocks_high}] (V2 had [0.15, 0.85])\")\n    print(f\"  Multi-layer logging: {config.analysis_layers_to_log}\")\n    print(f\"  Seed: {config.seed}\")\n    print(f\"  REINFORCE baseline: {config.use_baseline}\")\n    print(f\"  Checkpoint every: {config.save_every_n_steps} steps\")\n\n    print(f\"\\nVersions:\")\n    for pkg, ver in versions.items():\n        print(f\"  {pkg}: {ver}\")\n\n    # Load data\n    print(\"\\n\" + \"-\" * 40)\n    print(\"Loading datasets...\")\n\n    # Define paths to local benchmark data (if available)\n    gsm8k_path = None\n    math500_path = None\n\n    try:\n        script_dir = os.path.dirname(os.path.abspath(__file__))\n        project_root = os.path.dirname(script_dir)\n        benchmark_dir = os.path.join(project_root, \"evaluation\", \"benchmark_data\")\n        gsm8k_path = os.path.join(benchmark_dir, \"gsm8k_test.jsonl\")\n        math500_path = os.path.join(benchmark_dir, \"math_500.jsonl\")\n\n        if not os.path.exists(gsm8k_path):\n            gsm8k_path = None\n        if not os.path.exists(math500_path):\n            math500_path = None\n\n        print(f\"Local dataset check:\")\n        print(f\"  GSM8K: {'Found' if gsm8k_path else 'Not found'}\")\n        print(f\"  MATH-500: {'Found' if math500_path else 'Not found'}\")\n    except NameError:\n        print(\"Running in notebook environment - will download datasets from HuggingFace\")\n\n    gsm8k_data = load_gsm8k_data(\n        path=gsm8k_path,\n        num_samples=config.train_samples + config.eval_samples\n    )\n    random.shuffle(gsm8k_data)\n    train_data = gsm8k_data[:config.train_samples]\n    eval_data = gsm8k_data[config.train_samples:]\n\n    print(f\"Train: {len(train_data)}, Eval: {len(eval_data)}\")\n\n    hard_data = load_harder_math_data(\n        path=math500_path,\n        num_samples=200\n    )\n    print(f\"Hard problems: {len(hard_data)}\")\n\n    # Mix easy and hard (config-driven split)\n    n_hard = int(len(train_data) * config.hard_mix_ratio)\n    n_easy = len(train_data) - n_hard\n    train_data = train_data[:n_easy] + hard_data[:n_hard]\n    print(f\"Final mix: {n_easy} easy + {n_hard} hard = {len(train_data)} total\")\n    random.shuffle(train_data)\n\n    # Load model\n    print(\"\\n\" + \"-\" * 40)\n    print(\"Loading model...\")\n\n    if config.use_4bit:\n        bnb_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=config.bnb_4bit_quant_type,\n            bnb_4bit_compute_dtype=torch.bfloat16,\n            bnb_4bit_use_double_quant=True,\n        )\n    else:\n        bnb_config = None\n\n    tokenizer = AutoTokenizer.from_pretrained(config.model_name, trust_remote_code=True)\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n\n    model = AutoModelForCausalLM.from_pretrained(\n        config.model_name,\n        quantization_config=bnb_config,\n        device_map=\"auto\",\n        trust_remote_code=True,\n        torch_dtype=torch.bfloat16 if not config.use_4bit else None,\n    )\n\n    if config.use_4bit:\n        model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False)\n    \n    # CRITICAL FIX: Disable gradient checkpointing to restore gradient flow\n    model.gradient_checkpointing_disable()\n\n    lora_config = LoraConfig(\n        r=config.lora_r,\n        lora_alpha=config.lora_alpha,\n        target_modules=config.target_modules,\n        lora_dropout=config.lora_dropout,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\",\n    )\n\n    model = get_peft_model(model, lora_config)\n    model.print_trainable_parameters()\n\n    # Create trainer\n    trainer = RLOCovTrainerV2(model, tokenizer, config)\n\n    # Initial evaluation\n    print(\"\\n\" + \"=\" * 60)\n    print(\"INITIAL EVALUATION\")\n    print(\"=\" * 60)\n    initial_eval = trainer.evaluate(eval_data, num_samples=config.num_eval_samples)\n    print(f\"Accuracy: {initial_eval['accuracy']:.2f}%\")\n    print(f\"Structure Rate: {initial_eval['structure_rate']:.2f}%\")\n    print(f\"Goldilocks Rate: {initial_eval['goldilocks_rate']:.2f}%\")\n    print(f\"Avg Reward: {initial_eval['avg_reward']:.3f}\")\n\n    trainer.initial_accuracy = initial_eval['accuracy']\n    trainer.best_accuracy = initial_eval['accuracy']\n\n    # Training loop\n    print(\"\\n\" + \"=\" * 60)\n    print(\"TRAINING\")\n    print(\"=\" * 60)\n\n    for epoch in range(config.num_epochs):\n        print(f\"\\n--- Epoch {epoch + 1}/{config.num_epochs} ---\")\n        random.shuffle(train_data)\n\n        for i, item in enumerate(train_data):\n            result = trainer.train_step(item[\"question\"], item[\"answer\"])\n\n            # Logging\n            if trainer.global_step % config.log_every == 0:\n                stats = trainer.reward_calc.get_stats()\n                log_msg = f\"Step {trainer.global_step} | Loss: {result['loss']:.4f} | R: {result['reward']:.2f} | A: {result['advantage']:.2f}\"\n\n                if \"sim_mean\" in stats:\n                    log_msg += f\" | Sim@L{config.analysis_layer}: {stats['sim_mean']:.3f} [{stats['sim_min']:.2f}-{stats['sim_max']:.2f}]\"\n                    log_msg += f\" | GL: {stats['goldilocks_rate']*100:.0f}%\"\n\n                print(log_msg)\n\n                # V3: Log multi-layer calibration every 50 steps\n                if trainer.global_step % 50 == 0:\n                    layer_msg = \"  [CALIBRATION]\"\n                    for layer_idx in config.analysis_layers_to_log:\n                        key = f\"sim_L{layer_idx}_mean\"\n                        if key in stats:\n                            layer_msg += f\" L{layer_idx}={stats[key]:.3f}\"\n                    print(layer_msg)\n\n            # CHECKPOINTING (Issue #1)\n            if trainer.global_step % config.save_every_n_steps == 0:\n                ckpt_path = os.path.join(config.output_dir, f\"step_{trainer.global_step}\")\n                print(f\"\\n--- Saving checkpoint at step {trainer.global_step} ---\")\n                trainer.save_checkpoint(ckpt_path)\n                print()\n\n            # Evaluation\n            if trainer.global_step % config.eval_every_n_steps == 0:\n                print(\"\\n--- Evaluation ---\")\n                eval_result = trainer.evaluate(eval_data, num_samples=config.num_eval_samples)\n                print(f\"Accuracy: {eval_result['accuracy']:.2f}% | \"\n                      f\"Structure: {eval_result['structure_rate']:.2f}% | \"\n                      f\"Goldilocks: {eval_result['goldilocks_rate']:.2f}%\")\n\n                # CATASTROPHE DETECTION\n                if eval_result['accuracy'] < trainer.initial_accuracy - 20:\n                    print(\"    WARNING: Accuracy dropped >20% - possible catastrophic forgetting!\")\n                    print(\"    Consider stopping training or reducing learning rate.\")\n\n                if eval_result['accuracy'] > trainer.best_accuracy:\n                    trainer.best_accuracy = eval_result['accuracy']\n                    print(f\"    New best accuracy: {trainer.best_accuracy:.2f}%\")\n\n                    if config.save_on_best:\n                        best_path = os.path.join(config.output_dir, \"best\")\n                        print(f\"    Saving best checkpoint...\")\n                        trainer.save_checkpoint(best_path, is_best=True)\n\n                print(\"-\" * 40 + \"\\n\")\n\n    # Final evaluation\n    print(\"\\n\" + \"=\" * 60)\n    print(\"FINAL EVALUATION\")\n    print(\"=\" * 60)\n    final_eval = trainer.evaluate(eval_data, num_samples=config.num_eval_samples)\n    print(f\"Accuracy: {final_eval['accuracy']:.2f}%\")\n    print(f\"Structure Rate: {final_eval['structure_rate']:.2f}%\")\n    print(f\"Goldilocks Rate: {final_eval['goldilocks_rate']:.2f}%\")\n    print(f\"Avg Reward: {final_eval['avg_reward']:.3f}\")\n\n    # Summary\n    print(\"\\n\" + \"=\" * 60)\n    print(\"SUMMARY\")\n    print(\"=\" * 60)\n    print(f\"{'Metric':<20} {'Initial':>10} {'Final':>10} {'Delta':>10}\")\n    print(\"-\" * 50)\n    print(f\"{'Accuracy':<20} {initial_eval['accuracy']:>9.1f}% {final_eval['accuracy']:>9.1f}% \"\n          f\"{final_eval['accuracy'] - initial_eval['accuracy']:>+9.1f}%\")\n    print(f\"{'Goldilocks Rate':<20} {initial_eval['goldilocks_rate']:>9.1f}% {final_eval['goldilocks_rate']:>9.1f}% \"\n          f\"{final_eval['goldilocks_rate'] - initial_eval['goldilocks_rate']:>+9.1f}%\")\n    print(f\"{'Structure Rate':<20} {initial_eval['structure_rate']:>9.1f}% {final_eval['structure_rate']:>9.1f}% \"\n          f\"{final_eval['structure_rate'] - initial_eval['structure_rate']:>+9.1f}%\")\n\n    stats = trainer.reward_calc.get_stats()\n    if \"sim_mean\" in stats:\n        print(f\"\\nSimilarity Stats (primary layer {config.analysis_layer}):\")\n        print(f\"  Mean: {stats['sim_mean']:.3f}\")\n        print(f\"  Range: [{stats['sim_min']:.3f}, {stats['sim_max']:.3f}]\")\n        print(f\"  In Goldilocks: {stats['goldilocks_rate']*100:.1f}%\")\n\n        # V3: Show multi-layer comparison\n        print(f\"\\nMulti-Layer Calibration:\")\n        for layer_idx in config.analysis_layers_to_log:\n            key = f\"sim_L{layer_idx}_mean\"\n            if key in stats:\n                marker = \" <-- PRIMARY\" if layer_idx == config.analysis_layer else \"\"\n                print(f\"  Layer {layer_idx}: mean={stats[key]:.3f} \"\n                      f\"[{stats[f'sim_L{layer_idx}_min']:.3f}, {stats[f'sim_L{layer_idx}_max']:.3f}]{marker}\")\n\n    # SAVE FINAL CHECKPOINT\n    print(\"\\n\" + \"=\" * 60)\n    print(\"SAVING FINAL CHECKPOINT\")\n    print(\"=\" * 60)\n    final_path = os.path.join(config.output_dir, \"final\")\n    trainer.save_checkpoint(final_path, is_best=False)\n    print(f\"\\nAll artifacts saved to {config.output_dir}\")\n    print(f\"  - final/adapter : LoRA weights\")\n    print(f\"  - final/tokenizer : Tokenizer\")\n    print(f\"  - final/config_snapshot.json : Reproducibility info\")\n    print(f\"  - final/metrics.jsonl : Training metrics\")\n\n    return trainer\n\n\nif __name__ == \"__main__\":\n    trainer = main()\n",
   "id": "325092751fa70ea3"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}